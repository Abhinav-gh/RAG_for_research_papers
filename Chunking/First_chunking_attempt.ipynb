{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "083c9776",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "604cc8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain\n",
    "# !pip install pymupdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fda24581",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "file_path = \"../harrypotter.pdf\"\n",
    "docs = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ae1095",
   "metadata": {},
   "source": [
    "### Text Splitter (chunking strategy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a85dd34b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded and chunked the book content from the PDF with page numbers.\n",
      "Total number of chunks created: 1401\n",
      "\n",
      "Here is the content of the first chunk:\n",
      "---------------------------------------\n",
      "M\n",
      " \n",
      "CHAPTER  ONE\n",
      "THE BOY WHO LIVED\n",
      "r. and Mrs. Dursley, of number four, Privet Drive, were proud to say\n",
      "that they were perfectly normal, thank you very much. They were the\n",
      "last people you’d expect to be involved in anything strange or mysterious,\n",
      "because they just didn’t hold with such nonsense.\n",
      "Mr. Dursley was the director of a firm called Grunnings, which made drills.\n",
      "He was a big, beefy man with hardly any neck, although he did have a very\n",
      "---------------------------------------\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    with fitz.open(file_path) as pdf_doc:\n",
    "        for page_num, page in enumerate(pdf_doc):\n",
    "            # Extract text from the current page\n",
    "            page_text = page.get_text()\n",
    "\n",
    "            # Initialize a text splitter for this page.\n",
    "            # We will split the text from one page and add the page number as metadata to each chunk.\n",
    "            text_splitter = RecursiveCharacterTextSplitter(\n",
    "                chunk_size=500,\n",
    "                chunk_overlap=200,\n",
    "                separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    "            )\n",
    "            \n",
    "            # Split the text from the current page into chunks\n",
    "            page_chunks = text_splitter.create_documents([page_text])\n",
    "\n",
    "            # Add metadata to each chunk. We'll add the 1-based page number.\n",
    "            for chunk in page_chunks:\n",
    "                chunk.metadata.update({\"source\": file_path, \"page_number\": page_num + 1})\n",
    "                docs.append(chunk)\n",
    "\n",
    "    print(\"Successfully loaded and chunked the book content from the PDF with page numbers.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file '{file_path}' was not found. Please make sure the file exists.\")\n",
    "    exit()\n",
    "\n",
    "# Let's print some information about the chunks to verify\n",
    "print(f\"Total number of chunks created: {len(docs)}\")\n",
    "print(\"\\nHere is the content of the first chunk:\")\n",
    "print(\"---------------------------------------\")\n",
    "print(docs[0].page_content)\n",
    "print(\"---------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7292c80f",
   "metadata": {},
   "source": [
    "### Saving the chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270a1d4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved 1401 chunks to 'harry_potter_chunks.pkl'.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from langchain.schema import Document\n",
    "\n",
    "# Assuming the 'docs' list is already created from the previous step.\n",
    "\n",
    "file_path = \"harry_potter_chunks.pkl\"\n",
    "\n",
    "try:\n",
    "    with open(file_path, \"wb\") as f: # 'wb' mode for writing in binary\n",
    "        pickle.dump(docs, f)\n",
    "    print(f\"Successfully saved {len(docs)} chunks to '{file_path}'.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error saving file: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
